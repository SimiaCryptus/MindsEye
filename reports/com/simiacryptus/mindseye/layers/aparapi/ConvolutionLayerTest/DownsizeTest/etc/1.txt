Inputs: [
	[ [ 1.392, -0.684, 1.6, 0.336, 1.092, 1.152, -0.708 ], [ 1.416, 0.408, 0.74, -0.892, -1.172, 0.788, 0.44 ], [ 1.092, -0.964, 0.812, 0.208, 1.672, 1.9, -0.848 ] ],
	[ [ 1.584, 1.804, -1.052, -1.188, 0.676, -1.38, -1.616 ], [ 1.256, -0.972, 0.78, -1.348, 1.92, -0.976, 0.976 ], [ -0.092, 1.068, -0.94, -1.916, 0.984, 1.584, -1.14 ] ],
	[ [ 1.84, -1.268, -1.324, -0.268, 1.904, -0.344, 1.888 ], [ 1.78, 1.696, -0.928, -0.34, 1.64, -0.548, -0.352 ], [ 0.844, -0.196, 1.396, 0.848, -1.536, -1.64, 0.396 ] ]
]
Inputs Statistics: {meanExponent=-0.033195219468134356, negative=28, min=0.396, max=0.396, mean=0.24253968253968256, count=63.0, positive=35, stdDev=1.1765277514842551, zeros=0}
Output: [
	[ [ 1.5238399999999996, 3.6648319999999996, 1.9370559999999994 ] ]
]
Outputs Statistics: {meanExponent=0.34471187218881855, negative=0, min=1.9370559999999994, max=1.9370559999999994, mean=2.3752426666666664, count=3.0, positive=3, stdDev=0.927350114447732, zeros=0}
Feedback for input 0
Inputs Values: [
	[ [ 1.392, -0.684, 1.6, 0.336, 1.092, 1.152, -0.708 ], [ 1.416, 0.408, 0.74, -0.892, -1.172, 0.788, 0.44 ], [ 1.092, -0.964, 0.812, 0.208, 1.672, 1.9, -0.848 ] ],
	[ [ 1.584, 1.804, -1.052, -1.188, 0.676, -1.38, -1.616 ], [ 1.256, -0.972, 0.78, -1.348, 1.92, -0.976, 0.976 ], [ -0.092, 1.068, -0.94, -1.916, 0.984, 1.584, -1.14 ] ],
	[ [ 1.84, -1.268, -1.324, -0.268, 1.904, -0.344, 1.888 ], [ 1.78, 1.696, -0.928, -0.34, 1.64, -0.548, -0.352 ], [ 0.844, -0.196, 1.396, 0.848, -1.536, -1.64, 0.396 ] ]
]
Value Statistics: {meanExponent=-0.033195219468134356, negative=28, min=0.396, max=0.396, mean=0.24253968253968256, count=63.0, positive=35, stdDev=1.1765277514842551, zeros=0}
Implemented Feedback: [ [ 1.572, 1.04, 1.944 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], ... ]
Implemented Statistics: {meanExponent=-0.12292980168929335, negative=11, min=0.0, max=0.0, mean=0.003915343915343914, count=189.0, positive=10, stdDev=0.3945896444945585, zeros=168}
Measured Feedback: [ [ 1.5719999999985745, 1.0400000000032605, 1.9440000000026103 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], ... ]
Measured Statistics: {meanExponent=-0.12292980168909672, negative=11, min=0.0, max=0.0, mean=0.003915343915433007, count=189.0, positive=10, stdDev=0.39458964449458633, zeros=168}
Feedback Error: [ [ -1.425526363618701E-12, 3.2605029787191597E-12, 2.610356375498668E-12 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], ... ]
Error Statistics: {meanExponent=-12.126107852648238, negative=6, min=0.0, max=0.0, mean=8.909121236159185E-14, count=189.0, positive=15, stdDev=5.799746279629891E-13, zeros=168}
Learning Gradient for weight set 0
Weights: [ 1.572, 0.18, 0.492, 0.424, -1.428, -0.648, 1.156, 1.248, ... ]
Implemented Gradient: [ [ 1.392, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], ... ]
Implemented Statistics: {meanExponent=-0.04873386111627014, negative=6, min=0.0, max=0.0, mean=0.022116402116402114, count=567.0, positive=15, stdDev=0.20582523843928766, zeros=546}
Measured Gradient: [ [ 1.3920000000000599, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], ... ]
Measured Statistics: {meanExponent=-0.048733861116037745, negative=6, min=0.0, max=0.0, mean=0.022116402116415423, count=567.0, positive=15, stdDev=0.2058252384393572, zeros=546}
Gradient Error: [ [ 5.995204332975845E-14, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], ... ]
Error Statistics: {meanExponent=-12.360402952927673, negative=7, min=0.0, max=0.0, mean=1.3307109676373536E-14, count=567.0, positive=14, stdDev=1.9852802121759062E-13, zeros=546}
Finite-Difference Derivative Accuracy:
absoluteTol: 6.0568e-14 +- 3.3482e-13 [0.0000e+00 - 3.2605e-12] (756#)
relativeTol: 9.3018e-13 +- 1.4093e-12 [3.3077e-15 - 6.4476e-12] (42#)
